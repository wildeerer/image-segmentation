{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Image Segmentation",
   "id": "850d0a9b9e60d68a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T04:53:34.708083Z",
     "start_time": "2025-11-20T04:53:28.371680Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è Download failure, retrying 1/3 https://github.com/ultralytics/assets/releases/download/v8.3.0/sam2.1_b.pt... <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "######################################################################## 100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 403 layers, 80,850,178 parameters, 80,850,178 gradients\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(403, 80850178, 80850178, 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5,
   "source": [
    "from ultralytics import SAM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = SAM('sam2.1_b.pt')\n",
    "\n",
    "model.info()\n"
   ],
   "id": "41a89fc0505cf550"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:17:46.974797Z",
     "start_time": "2025-11-20T05:15:44.697791Z"
    }
   },
   "cell_type": "code",
   "source": "results = model(\"assets/bus.jpg\")",
   "id": "7087033974f00f89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/andrew/Desktop/code/nasa/cvat-nasa/assets/bus.jpg: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 122039.1ms\n",
      "Speed: 72.9ms preprocess, 122039.1ms inference, 39.5ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:18:30.576629Z",
     "start_time": "2025-11-20T05:18:29.815743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for result in results:\n",
    "    result.show()"
   ],
   "id": "87355e9bf8df4a33",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Video Segmentation",
   "id": "1f2d01b13ea15856"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-20T06:11:52.777204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics.models.sam import SAM2VideoPredictor\n",
    "\n",
    "video = \"assets/video.mp4\"\n",
    "overrides = dict(conf=0.25, task='segment', mode='predict', imgsz=1024, model='sam2.1_b.pt')\n",
    "\n",
    "predictor = SAM2VideoPredictor(overrides=overrides)\n",
    "results = predictor(video, points=[900,800], labels=[1])"
   ],
   "id": "63bf2cefaddbdb19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultralytics 8.3.229 üöÄ Python-3.11.5 torch-2.6.0 CPU (Apple M2)\n",
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/1001) /Users/andrew/Desktop/code/nasa/cvat-nasa/assets/video.mp4: 1024x1024 1 0, 4916.3ms\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T06:57:16.750674Z",
     "start_time": "2025-11-20T06:57:11.583165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for result in results:\n",
    "    result.show()"
   ],
   "id": "347757b11a5e8fc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultralytics 8.3.229 üöÄ Python-3.11.5 torch-2.6.0 CPU (Apple M2)\n",
      "WARNING ‚ö†Ô∏è Download failure, retrying 1/3 https://github.com/ultralytics/assets/releases/download/v8.3.0/sam2.1_b.pt... <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "######################################################################## 100.0%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No points are provided; please add points first",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresults\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/_contextlib.py:36\u001B[0m, in \u001B[0;36m_wrap_generator.<locals>.generator_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;66;03m# Issuing `None` to a generator fires it up\u001B[39;00m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m---> 36\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     40\u001B[0m             \u001B[38;5;66;03m# Forward the response to our caller and get its next request\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/engine/predictor.py:328\u001B[0m, in \u001B[0;36mBasePredictor.stream_inference\u001B[0;34m(self, source, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    326\u001B[0m \u001B[38;5;66;03m# Inference\u001B[39;00m\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m profilers[\u001B[38;5;241m1\u001B[39m]:\n\u001B[0;32m--> 328\u001B[0m     preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39membed:\n\u001B[1;32m    330\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m [preds] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(preds, torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;28;01melse\u001B[39;00m preds  \u001B[38;5;66;03m# yield embedding tensors\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/ultralytics/models/sam/predict.py:983\u001B[0m, in \u001B[0;36mSAM2VideoPredictor.inference\u001B[0;34m(self, im, bboxes, points, labels, masks)\u001B[0m\n\u001B[1;32m    981\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minference_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobj_idx_to_id\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(output_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcond_frame_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 983\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo points are provided; please add points first\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    985\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m frame \u001B[38;5;129;01min\u001B[39;00m consolidated_frame_inds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcond_frame_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    986\u001B[0m     storage_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcond_frame_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: No points are provided; please add points first"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ea4baf58fcc06600"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
